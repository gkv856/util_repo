{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MNIST Digit Recognition using Feed Forward Neural Network\n",
        "\n",
        "## Introduction\n",
        "\n",
        "In this notebook, we aim to build a Feed Forward Neural Network (also known as a Multilayer Perceptron or MLP) to recognize handwritten digits from the MNIST dataset.\n",
        "\n",
        "## Dataset\n",
        "\n",
        "The [MNIST](https://pytorch.org/vision/main/generated/torchvision.datasets.MNIST.html) (Modified National Institute of Standards and Technology) database is a large database of handwritten digits that is commonly used for training and testing in the field of machine learning. The dataset contains 60,000 training images and 10,000 testing images.\n",
        "\n",
        "Each image in the MNIST dataset is a 28x28 grayscale image containing a digit from 0 to 9, and it is associated with a label (0-9).\n",
        "\n",
        "## Objective\n",
        "\n",
        "The objective of this notebook is to train a Feed Forward Neural Network to map each input image to the correct digit label. By training on the images and their associated labels from the training part of the dataset, it will 'learn' to predict which digit is written in the image.\n",
        "\n",
        "## Neural Network Architecture\n",
        "\n",
        "Our Feed Forward Neural Network will consist of an input layer, few hidden layers, and an output layer:\n",
        "* The **input layer** will have 784 neurons (or 'units'), one for each pixel in the input image.\n",
        "* The **hidden layers** will apply transformations to the inputs before reaching the output layer. The exact number of hidden layers and the number of neurons in these layers is a model hyperparameter.\n",
        "* The **output layer** will have 10 neurons, representing the scores for each of the 10 possible labels (0-9).\n",
        "\n",
        "The learning process involves adjusting the weights and biases of the network to improve the accuracy of predictions. We'll be using a variant of stochastic gradient descent to optimize the network's parameters.\n",
        "\n",
        "## Libraries\n",
        "\n",
        "We will be using `PyTorch`, a machine learning library in Python, for constructing and training our neural network. Other libraries such as `NumPy` and `Matplotlib` will also be used for data manipulation and visualization respectively.\n",
        "\n",
        "By the end of this notebook, you will have a trained model which will be able to accurately predict the digit present in a given image.\n"
      ],
      "metadata": {
        "id": "vx8z6VGCJaFu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing libraries"
      ],
      "metadata": {
        "id": "vj9XC3aoJtmz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "id": "SAixq-XpI08B"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as T\n",
        "import torch.autograd as Variable"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining hyper-parameters"
      ],
      "metadata": {
        "id": "BqKc_YiCKN2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hp = {\n",
        "  \"input_size\": 28*28, # 24x24= 764 pixels\n",
        "  \"hidden_size\": 400, # number of hidden neurons\n",
        "  \"out_size\": 10, # number of classes [0, 9] digits\n",
        "  \"epochs\": 10, # how many times will we pas sour entire dataset of 60k images to our network to learn from it.\n",
        "  \"batch_size\": 100, # for one iteration, how many images we will send to the network in one go\n",
        "  \"learning_rate\": 0.001, # how fast the model will learn\n",
        "  }"
      ],
      "metadata": {
        "id": "naNk8kOlKIXF"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Downloading data from MNIST dataset"
      ],
      "metadata": {
        "id": "ExPnkmynLytY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.MNIST(root=\"./data\",\n",
        "                               train=True,\n",
        "                               transform=T.ToTensor(),\n",
        "                               download=True)\n",
        "\n",
        "test_dataset = datasets.MNIST(root=\"./data\",\n",
        "                               train=False,\n",
        "                               transform=T.ToTensor(),\n",
        "                               download=True)"
      ],
      "metadata": {
        "id": "X4GlXQbALLB0"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing Dataloader\n",
        "- Dataloader will help us get the raw images into iterable format\n",
        "- This iterable format of data will be used to send to the network for learning"
      ],
      "metadata": {
        "id": "CzhZY7y6Lv_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader as DL"
      ],
      "metadata": {
        "id": "YUBb7GxLLdh9"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DL(dataset=train_dataset,\n",
        "                  batch_size=hp[\"batch_size\"],\n",
        "                  shuffle=True)\n"
      ],
      "metadata": {
        "id": "xdEkjrA7LqK9"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = DL(dataset=train_dataset,\n",
        "                  batch_size=hp[\"batch_size\"],\n",
        "                  shuffle=True)\n"
      ],
      "metadata": {
        "id": "RAMuagl4MPzS"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# there are two ways of getting data out of the loader\n",
        "# 1 using for loop\n",
        "for train_features, train_labels in train_loader:\n",
        "  print(train_features.shape, train_labels.shape)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gkp0HWW7Kpv9",
        "outputId": "4c98d414-7870-4024-84cb-009fb1ca3009"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100, 1, 28, 28]) torch.Size([100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2 using for iter and next\n",
        "train_features, train_labels = next(iter(train_loader))"
      ],
      "metadata": {
        "id": "9If4U0gWWJVt"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features.shape, train_labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kGtIwX6WKoy",
        "outputId": "985d20a9-d4d7-47bb-f02d-d6bc25733ec3"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([100, 1, 28, 28]), torch.Size([100]))"
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualizing the data"
      ],
      "metadata": {
        "id": "fs-QeuJaf25N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "96R6N2SKgDvm"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_img = 3\n",
        "fig, axs = plt.subplots(1, num_img)\n",
        "\n",
        "for i in range(0, num_img):\n",
        "    img = train_features[i]\n",
        "    img = torch.squeeze(img, dim=0)\n",
        "    axs[i].imshow(img)\n",
        "\n",
        "    # Convert label to int and then to string before setting the title\n",
        "    label = int(train_labels[i].detach().cpu().numpy())\n",
        "    axs[i].set_title('Image ' + str(label))\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "j5oFuZZLJxp3",
        "outputId": "4c9a8ae2-abe0-4892-cc87-4ae8987b78e2"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Designing the Neural Network\n",
        "\n",
        "## Class Definition\n",
        "\n",
        "We create a class `Net` which builds upon PyTorch's `nn.Module` base class. This class contains methods and attributes necessary for creating a customizable neural network architecture.\n",
        "\n",
        "### Structure\n",
        "\n",
        "This neural network consists of the following sequence of layers and functions:\n",
        "\n",
        "* A Linear (Fully-Connected) Layer (also known as 'Dense' layer)\n",
        "* ReLU (Rectified Linear Unit) Activation Function\n",
        "* Another Linear Layer\n",
        "* Another Linear Layer\n",
        "\n",
        "Now, let's break down each of these components:\n",
        "\n",
        "- **First Linear Layer (`fc1`):** This layer is a linear transformation,  `y = Wx + b`, where `W` and `b` are learnable parameters. This layer takes in `input_size` number of features from the input data and transforms them into an intermediate `hidden_size` dimensional space.\n",
        "\n",
        "- **ReLU Activation (`relu`):** Non-linear activation function to introduce non-linearity into the model, hence allowing the network to learn more complex functions. It squashes all negative values to zero and maintains positive values as is. We use ReLU after first linear layer.\n",
        "\n",
        "- **Second Linear Layer (`fc2`):** This layer takes in `hidden_size` features, applies a linear transformation, and retains the same number of features (`hidden_size`).\n",
        "\n",
        "- **Third Linear Layer (`fc3`):** The final linear layer takes in `hidden_size` features and transforms them into `out_size` dimensions. This `out_size` typically corresponds to the number of output classes of the problem at hand.\n",
        "\n",
        "### Forward method\n",
        "\n",
        "The `forward` method of the class defines the forward pass computations of the neural network. PyTorch's differentiable runtime will automatically generate the backward pass computations (gradients) for us.\n",
        "\n",
        "* The initial input tensor `x` goes through the first linear layer (`fc1`) and the non-linear activation function (ReLU).\n",
        "\n",
        "* The output is again passed through the second linear layer (`fc2`).\n",
        "\n",
        "* The output from this layer is finally passed through the third linear layer (`fc3`).\n",
        "\n",
        "This final linear layer's output could be directly used with a certain types of loss function (like CrossEntropyLoss) for calculating the loss and updating the model parameters during training.\n",
        "\n",
        "This `Net` class structure provides a base for a simple, customizable feed-forward network that can be used for classification tasks with PyTorch.\n",
        "\n",
        "Note: We do not apply a final activation function at the end of the model, as we expect to use this output directly in a loss function that includes that activation. For example, when using PyTorch's cross-entropy loss function, this includes a softmax activation. However, this depends on the specific use-case and the method of training the model."
      ],
      "metadata": {
        "id": "AVfArh95jX2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    \"\"\"\n",
        "    Define a neural network class 'Net' which inherits from the 'nn.Module' class of PyTorch.\n",
        "    'nn.Module' is the base class for all neural network modules.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, out_size):\n",
        "        \"\"\"\n",
        "        Initialize the network structure.\n",
        "\n",
        "        Parameters:\n",
        "        input_size (int): Number of input neurons, equivalent to the number of input features.\n",
        "        hidden_size (int): Number of neurons in the hidden layers.\n",
        "        out_size (int): Number of output neurons, equivalent to the number of target classes.\n",
        "        \"\"\"\n",
        "        # Call the init of nn.Module.\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        # Define the first linear layer with 'input_size' inputs and 'hidden_size' outputs\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "\n",
        "        # Define the activation function as ReLU (Rectified Linear Unit)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        # Define the second linear layer with 'hidden_size' inputs and 'hidden_size' outputs.\n",
        "        # This layer takes the outputs from the first layer as inputs.\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "        # Define the third linear layer with 'hidden_size' inputs and 'out_size' outputs.\n",
        "        # This one will take the outputs from the second layer as inputs.\n",
        "        self.fc3 = nn.Linear(hidden_size, out_size)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Defines the computation performed at every call.\n",
        "        Note: 'forward' gets automatically called when we pass data to a nn.Module object\n",
        "\n",
        "        Parameters:\n",
        "        x (torch.Tensor): The input tensors with shape [batch_size, input_size].\n",
        "        \"\"\"\n",
        "\n",
        "        # Pass the input tensors through the first linear layer and then apply the activation function\n",
        "        out = self.relu(self.fc1(x))\n",
        "\n",
        "        # Then, pass through the second linear layer and again apply the activation function\n",
        "        out = self.fc2(out)\n",
        "\n",
        "        # Finally, pass through the third linear layer\n",
        "        out = self.fc3(out)\n",
        "\n",
        "        # Here we don't apply an activation at the end of the last layer because PyTorch's\n",
        "        # cross entropy loss function used for training includes softmax by default.\n",
        "\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "LU8w__mQjcFi"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if CUDA is available, else use CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sz5gu3aslla5",
        "outputId": "068c31d7-c0c9-4d00-c7df-c8504b8c6389"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the network. Make sure to use appropriate input_size, hidden_size and out_size\n",
        "def getFreshModel():\n",
        "  net = Net(hp[\"input_size\"], hp[\"hidden_size\"], hp[\"out_size\"])\n",
        "  net.to(device)\n",
        "  return net\n",
        "\n",
        "net = getFreshModel()\n",
        "# Send the model to the device\n"
      ],
      "metadata": {
        "id": "oWGzCV87kC1l"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualizing the Model"
      ],
      "metadata": {
        "id": "nBlv6KtpmVMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchviz\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLuyKz8Hl3Zm",
        "outputId": "09080a3a-7939-4cb8-f7ff-76df9db192e0"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchviz in /usr/local/lib/python3.10/dist-packages (0.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchviz) (2.2.1+cu121)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from torchviz) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->torchviz) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchviz) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchviz) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchviz import make_dot\n",
        "\n",
        "# To visualize the model, we need to create a dummy input\n",
        "# The dummy input size should match with the input size of the model\n",
        "dummy_input = train_features[0].to(device)\n",
        "dummy_input  = dummy_input.view(-1, 28*28)\n",
        "# We use the forward pass on the dummy input\n",
        "out = net(dummy_input)\n",
        "\n",
        "# Generate the graph using the dummy input to visualize the architecture\n",
        "dot = make_dot(out, params=dict(net.named_parameters()))\n",
        "dot.render(\"model_architecture.gv\", view=True)\n",
        "\n",
        "# Display the graph\n",
        "dot\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "id": "A-lDilasmIfs",
        "outputId": "65c340e3-9a37-45a5-e293-f34f84f9696c"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"519pt\" height=\"479pt\"\n viewBox=\"0.00 0.00 519.00 479.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 475)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-475 515,-475 515,4 -4,4\"/>\n<!-- 132403806282160 -->\n<g id=\"node1\" class=\"node\">\n<title>132403806282160</title>\n<polygon fill=\"#caff70\" stroke=\"black\" points=\"282,-31 217,-31 217,0 282,0 282,-31\"/>\n<text text-anchor=\"middle\" x=\"249.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> (1, 10)</text>\n</g>\n<!-- 132403807719952 -->\n<g id=\"node2\" class=\"node\">\n<title>132403807719952</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"300,-86 199,-86 199,-67 300,-67 300,-86\"/>\n<text text-anchor=\"middle\" x=\"249.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">AddmmBackward0</text>\n</g>\n<!-- 132403807719952&#45;&gt;132403806282160 -->\n<g id=\"edge19\" class=\"edge\">\n<title>132403807719952&#45;&gt;132403806282160</title>\n<path fill=\"none\" stroke=\"black\" d=\"M249.5,-66.79C249.5,-60.07 249.5,-50.4 249.5,-41.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"253,-41.19 249.5,-31.19 246,-41.19 253,-41.19\"/>\n</g>\n<!-- 132403807727728 -->\n<g id=\"node3\" class=\"node\">\n<title>132403807727728</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"132,-141 31,-141 31,-122 132,-122 132,-141\"/>\n<text text-anchor=\"middle\" x=\"81.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 132403807727728&#45;&gt;132403807719952 -->\n<g id=\"edge1\" class=\"edge\">\n<title>132403807727728&#45;&gt;132403807719952</title>\n<path fill=\"none\" stroke=\"black\" d=\"M108.49,-121.98C136.7,-113.09 181.14,-99.07 212.58,-89.15\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"213.81,-92.43 222.3,-86.08 211.71,-85.75 213.81,-92.43\"/>\n</g>\n<!-- 132403841808192 -->\n<g id=\"node4\" class=\"node\">\n<title>132403841808192</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"65,-207 0,-207 0,-177 65,-177 65,-207\"/>\n<text text-anchor=\"middle\" x=\"32.5\" y=\"-195\" font-family=\"monospace\" font-size=\"10.00\">fc3.bias</text>\n<text text-anchor=\"middle\" x=\"32.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\"> (10)</text>\n</g>\n<!-- 132403841808192&#45;&gt;132403807727728 -->\n<g id=\"edge2\" class=\"edge\">\n<title>132403841808192&#45;&gt;132403807727728</title>\n<path fill=\"none\" stroke=\"black\" d=\"M44.36,-176.84C51.4,-168.43 60.36,-157.74 67.71,-148.96\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"70.42,-151.18 74.16,-141.27 65.05,-146.68 70.42,-151.18\"/>\n</g>\n<!-- 132403807723264 -->\n<g id=\"node5\" class=\"node\">\n<title>132403807723264</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"300,-141 199,-141 199,-122 300,-122 300,-141\"/>\n<text text-anchor=\"middle\" x=\"249.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">AddmmBackward0</text>\n</g>\n<!-- 132403807723264&#45;&gt;132403807719952 -->\n<g id=\"edge3\" class=\"edge\">\n<title>132403807723264&#45;&gt;132403807719952</title>\n<path fill=\"none\" stroke=\"black\" d=\"M249.5,-121.75C249.5,-114.8 249.5,-104.85 249.5,-96.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"253,-96.09 249.5,-86.09 246,-96.09 253,-96.09\"/>\n</g>\n<!-- 132403807718608 -->\n<g id=\"node6\" class=\"node\">\n<title>132403807718608</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"184,-201.5 83,-201.5 83,-182.5 184,-182.5 184,-201.5\"/>\n<text text-anchor=\"middle\" x=\"133.5\" y=\"-189.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 132403807718608&#45;&gt;132403807723264 -->\n<g id=\"edge4\" class=\"edge\">\n<title>132403807718608&#45;&gt;132403807723264</title>\n<path fill=\"none\" stroke=\"black\" d=\"M150.62,-182.37C169.72,-172.73 200.87,-157.03 223.1,-145.81\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"224.96,-148.8 232.31,-141.17 221.81,-142.55 224.96,-148.8\"/>\n</g>\n<!-- 132403841803632 -->\n<g id=\"node7\" class=\"node\">\n<title>132403841803632</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"166,-273 101,-273 101,-243 166,-243 166,-273\"/>\n<text text-anchor=\"middle\" x=\"133.5\" y=\"-261\" font-family=\"monospace\" font-size=\"10.00\">fc2.bias</text>\n<text text-anchor=\"middle\" x=\"133.5\" y=\"-250\" font-family=\"monospace\" font-size=\"10.00\"> (400)</text>\n</g>\n<!-- 132403841803632&#45;&gt;132403807718608 -->\n<g id=\"edge5\" class=\"edge\">\n<title>132403841803632&#45;&gt;132403807718608</title>\n<path fill=\"none\" stroke=\"black\" d=\"M133.5,-242.8C133.5,-233.7 133.5,-221.79 133.5,-211.9\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"137,-211.84 133.5,-201.84 130,-211.84 137,-211.84\"/>\n</g>\n<!-- 132403807720768 -->\n<g id=\"node8\" class=\"node\">\n<title>132403807720768</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"297,-201.5 202,-201.5 202,-182.5 297,-182.5 297,-201.5\"/>\n<text text-anchor=\"middle\" x=\"249.5\" y=\"-189.5\" font-family=\"monospace\" font-size=\"10.00\">ReluBackward0</text>\n</g>\n<!-- 132403807720768&#45;&gt;132403807723264 -->\n<g id=\"edge6\" class=\"edge\">\n<title>132403807720768&#45;&gt;132403807723264</title>\n<path fill=\"none\" stroke=\"black\" d=\"M249.5,-182.37C249.5,-174.25 249.5,-161.81 249.5,-151.39\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"253,-151.17 249.5,-141.17 246,-151.17 253,-151.17\"/>\n</g>\n<!-- 132403807719520 -->\n<g id=\"node9\" class=\"node\">\n<title>132403807719520</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"285,-267.5 184,-267.5 184,-248.5 285,-248.5 285,-267.5\"/>\n<text text-anchor=\"middle\" x=\"234.5\" y=\"-255.5\" font-family=\"monospace\" font-size=\"10.00\">AddmmBackward0</text>\n</g>\n<!-- 132403807719520&#45;&gt;132403807720768 -->\n<g id=\"edge7\" class=\"edge\">\n<title>132403807719520&#45;&gt;132403807720768</title>\n<path fill=\"none\" stroke=\"black\" d=\"M236.52,-248.37C238.7,-239.07 242.24,-223.98 245.07,-211.9\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"248.54,-212.44 247.41,-201.91 241.72,-210.84 248.54,-212.44\"/>\n</g>\n<!-- 132403807721920 -->\n<g id=\"node10\" class=\"node\">\n<title>132403807721920</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"188,-333.5 87,-333.5 87,-314.5 188,-314.5 188,-333.5\"/>\n<text text-anchor=\"middle\" x=\"137.5\" y=\"-321.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 132403807721920&#45;&gt;132403807719520 -->\n<g id=\"edge8\" class=\"edge\">\n<title>132403807721920&#45;&gt;132403807719520</title>\n<path fill=\"none\" stroke=\"black\" d=\"M150.58,-314.37C166.56,-303.82 193.83,-285.84 212.93,-273.23\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"214.9,-276.13 221.32,-267.7 211.04,-270.28 214.9,-276.13\"/>\n</g>\n<!-- 132403841808432 -->\n<g id=\"node11\" class=\"node\">\n<title>132403841808432</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"170,-405 105,-405 105,-375 170,-375 170,-405\"/>\n<text text-anchor=\"middle\" x=\"137.5\" y=\"-393\" font-family=\"monospace\" font-size=\"10.00\">fc1.bias</text>\n<text text-anchor=\"middle\" x=\"137.5\" y=\"-382\" font-family=\"monospace\" font-size=\"10.00\"> (400)</text>\n</g>\n<!-- 132403841808432&#45;&gt;132403807721920 -->\n<g id=\"edge9\" class=\"edge\">\n<title>132403841808432&#45;&gt;132403807721920</title>\n<path fill=\"none\" stroke=\"black\" d=\"M137.5,-374.8C137.5,-365.7 137.5,-353.79 137.5,-343.9\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"141,-343.84 137.5,-333.84 134,-343.84 141,-343.84\"/>\n</g>\n<!-- 132403807730272 -->\n<g id=\"node12\" class=\"node\">\n<title>132403807730272</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"283,-333.5 206,-333.5 206,-314.5 283,-314.5 283,-333.5\"/>\n<text text-anchor=\"middle\" x=\"244.5\" y=\"-321.5\" font-family=\"monospace\" font-size=\"10.00\">TBackward0</text>\n</g>\n<!-- 132403807730272&#45;&gt;132403807719520 -->\n<g id=\"edge10\" class=\"edge\">\n<title>132403807730272&#45;&gt;132403807719520</title>\n<path fill=\"none\" stroke=\"black\" d=\"M243.15,-314.37C241.7,-305.07 239.34,-289.98 237.45,-277.9\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"240.89,-277.25 235.89,-267.91 233.98,-278.33 240.89,-277.25\"/>\n</g>\n<!-- 132403807725856 -->\n<g id=\"node13\" class=\"node\">\n<title>132403807725856</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"295,-399.5 194,-399.5 194,-380.5 295,-380.5 295,-399.5\"/>\n<text text-anchor=\"middle\" x=\"244.5\" y=\"-387.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 132403807725856&#45;&gt;132403807730272 -->\n<g id=\"edge11\" class=\"edge\">\n<title>132403807725856&#45;&gt;132403807730272</title>\n<path fill=\"none\" stroke=\"black\" d=\"M244.5,-380.37C244.5,-371.16 244.5,-356.29 244.5,-344.27\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"248,-343.91 244.5,-333.91 241,-343.91 248,-343.91\"/>\n</g>\n<!-- 132403843819504 -->\n<g id=\"node14\" class=\"node\">\n<title>132403843819504</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"286,-471 203,-471 203,-441 286,-441 286,-471\"/>\n<text text-anchor=\"middle\" x=\"244.5\" y=\"-459\" font-family=\"monospace\" font-size=\"10.00\">fc1.weight</text>\n<text text-anchor=\"middle\" x=\"244.5\" y=\"-448\" font-family=\"monospace\" font-size=\"10.00\"> (400, 784)</text>\n</g>\n<!-- 132403843819504&#45;&gt;132403807725856 -->\n<g id=\"edge12\" class=\"edge\">\n<title>132403843819504&#45;&gt;132403807725856</title>\n<path fill=\"none\" stroke=\"black\" d=\"M244.5,-440.8C244.5,-431.7 244.5,-419.79 244.5,-409.9\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"248,-409.84 244.5,-399.84 241,-409.84 248,-409.84\"/>\n</g>\n<!-- 132403807729984 -->\n<g id=\"node15\" class=\"node\">\n<title>132403807729984</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"392,-201.5 315,-201.5 315,-182.5 392,-182.5 392,-201.5\"/>\n<text text-anchor=\"middle\" x=\"353.5\" y=\"-189.5\" font-family=\"monospace\" font-size=\"10.00\">TBackward0</text>\n</g>\n<!-- 132403807729984&#45;&gt;132403807723264 -->\n<g id=\"edge13\" class=\"edge\">\n<title>132403807729984&#45;&gt;132403807723264</title>\n<path fill=\"none\" stroke=\"black\" d=\"M338.15,-182.37C321.18,-172.82 293.6,-157.31 273.71,-146.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"275.34,-143.02 264.91,-141.17 271.91,-149.12 275.34,-143.02\"/>\n</g>\n<!-- 132403807717408 -->\n<g id=\"node16\" class=\"node\">\n<title>132403807717408</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"404,-267.5 303,-267.5 303,-248.5 404,-248.5 404,-267.5\"/>\n<text text-anchor=\"middle\" x=\"353.5\" y=\"-255.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 132403807717408&#45;&gt;132403807729984 -->\n<g id=\"edge14\" class=\"edge\">\n<title>132403807717408&#45;&gt;132403807729984</title>\n<path fill=\"none\" stroke=\"black\" d=\"M353.5,-248.37C353.5,-239.16 353.5,-224.29 353.5,-212.27\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"357,-211.91 353.5,-201.91 350,-211.91 357,-211.91\"/>\n</g>\n<!-- 132403841804992 -->\n<g id=\"node17\" class=\"node\">\n<title>132403841804992</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"395,-339 312,-339 312,-309 395,-309 395,-339\"/>\n<text text-anchor=\"middle\" x=\"353.5\" y=\"-327\" font-family=\"monospace\" font-size=\"10.00\">fc2.weight</text>\n<text text-anchor=\"middle\" x=\"353.5\" y=\"-316\" font-family=\"monospace\" font-size=\"10.00\"> (400, 400)</text>\n</g>\n<!-- 132403841804992&#45;&gt;132403807717408 -->\n<g id=\"edge15\" class=\"edge\">\n<title>132403841804992&#45;&gt;132403807717408</title>\n<path fill=\"none\" stroke=\"black\" d=\"M353.5,-308.8C353.5,-299.7 353.5,-287.79 353.5,-277.9\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"357,-277.84 353.5,-267.84 350,-277.84 357,-277.84\"/>\n</g>\n<!-- 132403807731664 -->\n<g id=\"node18\" class=\"node\">\n<title>132403807731664</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"447,-141 370,-141 370,-122 447,-122 447,-141\"/>\n<text text-anchor=\"middle\" x=\"408.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">TBackward0</text>\n</g>\n<!-- 132403807731664&#45;&gt;132403807719952 -->\n<g id=\"edge16\" class=\"edge\">\n<title>132403807731664&#45;&gt;132403807719952</title>\n<path fill=\"none\" stroke=\"black\" d=\"M382.95,-121.98C356.38,-113.13 314.56,-99.19 284.83,-89.28\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"285.84,-85.92 275.25,-86.08 283.63,-92.56 285.84,-85.92\"/>\n</g>\n<!-- 132403807731376 -->\n<g id=\"node19\" class=\"node\">\n<title>132403807731376</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"511,-201.5 410,-201.5 410,-182.5 511,-182.5 511,-201.5\"/>\n<text text-anchor=\"middle\" x=\"460.5\" y=\"-189.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 132403807731376&#45;&gt;132403807731664 -->\n<g id=\"edge17\" class=\"edge\">\n<title>132403807731376&#45;&gt;132403807731664</title>\n<path fill=\"none\" stroke=\"black\" d=\"M452.83,-182.37C444.99,-173.55 432.64,-159.66 422.96,-148.77\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"425.46,-146.32 416.2,-141.17 420.23,-150.97 425.46,-146.32\"/>\n</g>\n<!-- 132403841798032 -->\n<g id=\"node20\" class=\"node\">\n<title>132403841798032</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"499,-273 422,-273 422,-243 499,-243 499,-273\"/>\n<text text-anchor=\"middle\" x=\"460.5\" y=\"-261\" font-family=\"monospace\" font-size=\"10.00\">fc3.weight</text>\n<text text-anchor=\"middle\" x=\"460.5\" y=\"-250\" font-family=\"monospace\" font-size=\"10.00\"> (10, 400)</text>\n</g>\n<!-- 132403841798032&#45;&gt;132403807731376 -->\n<g id=\"edge18\" class=\"edge\">\n<title>132403841798032&#45;&gt;132403807731376</title>\n<path fill=\"none\" stroke=\"black\" d=\"M460.5,-242.8C460.5,-233.7 460.5,-221.79 460.5,-211.9\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"464,-211.84 460.5,-201.84 457,-211.84 464,-211.84\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x786ba9ed0940>"
            ]
          },
          "metadata": {},
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gR94zdOSqtam",
        "outputId": "d06ab83a-7184-44c4-e1df-f98eb135a318"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9enkiq7qxe4",
        "outputId": "e77ab463-2ee7-469b-8897-ef233bf935f0"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0584, -0.0924,  0.0387, -0.0485,  0.0234,  0.0215,  0.0317, -0.0968,\n",
              "         -0.0931, -0.0653]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualizing the model summary"
      ],
      "metadata": {
        "id": "LjjnnZo4n6I8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n"
      ],
      "metadata": {
        "id": "v1QxJqvaoCkq"
      },
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(net, input_size=(1, hp[\"input_size\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2plQSBEmn7pB",
        "outputId": "a7095575-e48e-496a-ee77-aa1a795a085d"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1               [-1, 1, 400]         314,000\n",
            "              ReLU-2               [-1, 1, 400]               0\n",
            "            Linear-3               [-1, 1, 400]         160,400\n",
            "            Linear-4                [-1, 1, 10]           4,010\n",
            "================================================================\n",
            "Total params: 478,410\n",
            "Trainable params: 478,410\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.01\n",
            "Params size (MB): 1.82\n",
            "Estimated Total Size (MB): 1.84\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loss function and Optimizer\n",
        "- Refer to this video if you are not sure how Loss Functions work\n",
        "- Refer to this video if you are not sure how Optimiers work"
      ],
      "metadata": {
        "id": "fzsCfNKYos6L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html\n",
        "# note that CrossEntropyLoss comes with a Softmax layer therefore we dont have to create that layer in our Net model\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "loss_fn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQE4Rn2TowNM",
        "outputId": "6da336aa-5653-4f80-b38e-e7470ffafb19"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CrossEntropyLoss()"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://pytorch.org/docs/stable/generated/torch.optim.Adam.html\n",
        "net = getFreshModel()\n",
        "optim_fn = torch.optim.Adam(net.parameters(),\n",
        "                            lr=hp[\"learning_rate\"])\n",
        "optim_fn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10tAt8aZpDCB",
        "outputId": "74298d20-9fcf-4ae1-bcae-36ab5feebb8b"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Adam (\n",
              "Parameter Group 0\n",
              "    amsgrad: False\n",
              "    betas: (0.9, 0.999)\n",
              "    capturable: False\n",
              "    differentiable: False\n",
              "    eps: 1e-08\n",
              "    foreach: None\n",
              "    fused: None\n",
              "    lr: 0.001\n",
              "    maximize: False\n",
              "    weight_decay: 0\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in net.parameters():\n",
        "  print(type(param), param.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuJ2bl_BqY7W",
        "outputId": "41ec7fe5-38b6-475a-9094-25bd771ea046"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.nn.parameter.Parameter'> torch.Size([400, 784])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([400])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([400, 400])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([400])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([10, 400])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training the model"
      ],
      "metadata": {
        "id": "KG8ShD-qohOD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize variables to track the total number of correctly predicted samples during training\n",
        "total_train = 0\n",
        "correct_train = 0\n",
        "\n",
        "# Obtain a fresh instance of the neural network model\n",
        "net = getFreshModel()\n",
        "\n",
        "# Define the optimizer for updating the model parameters using the Adam optimizer with specified learning rate\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=hp[\"learning_rate\"])\n",
        "\n",
        "# Loop over the specified number of epochs for training the model\n",
        "for epoch in range(0, hp[\"epochs\"]):\n",
        "    # Reset the count of correctly predicted samples for each epoch\n",
        "    correct_train = 0\n",
        "    # Initialize a variable to track the cumulative loss during training for each epoch\n",
        "    running_loss = 0\n",
        "\n",
        "    # Iterate over the batches of data in the training dataset\n",
        "    for i, (imgs, labels) in enumerate(train_loader):\n",
        "        # Reshape the input images to a 1D tensor\n",
        "        imgs = imgs.view(-1, 28*28)\n",
        "        # Move the input images and labels to the appropriate device (e.g., CPU or GPU)\n",
        "        imgs = imgs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass: compute the predicted outputs by passing the input images through the network\n",
        "        outputs = net(imgs)\n",
        "\n",
        "        # Compute the predicted classes by selecting the class with the highest probability\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        # Update the count of correctly predicted samples for this batch\n",
        "        correct_train += (predicted == labels).sum()\n",
        "\n",
        "        # Compute the loss between the predicted outputs and the true labels\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "        # Accumulate the loss for this batch\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Backpropagation: compute gradients of the loss with respect to the model parameters\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        # Update the model parameters using the computed gradients\n",
        "        optimizer.step()\n",
        "\n",
        "    # Print the average training loss and accuracy for the current epoch\n",
        "    print('Epoch [{}/{}], Training Loss: {:.3f}, Training Accuracy: {:.3f}%'.format(\n",
        "        epoch+1, hp[\"epochs\"], running_loss/len(train_loader), (100*correct_train.double()/len(train_dataset))))\n",
        "\n",
        "# Print a message indicating that training is complete\n",
        "print(\"Done Training\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2pJmzGgoj1P",
        "outputId": "4ed85d08-896d-4066-fb9b-7b5ddf02c68f"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Training Loss: 0.249, Training Accuracy: 92.605%\n",
            "Epoch [2/10], Training Loss: 0.093, Training Accuracy: 97.153%\n",
            "Epoch [3/10], Training Loss: 0.062, Training Accuracy: 98.028%\n",
            "Epoch [4/10], Training Loss: 0.046, Training Accuracy: 98.608%\n",
            "Epoch [5/10], Training Loss: 0.037, Training Accuracy: 98.783%\n",
            "Epoch [6/10], Training Loss: 0.029, Training Accuracy: 99.067%\n",
            "Epoch [7/10], Training Loss: 0.025, Training Accuracy: 99.137%\n",
            "Epoch [8/10], Training Loss: 0.023, Training Accuracy: 99.240%\n",
            "Epoch [9/10], Training Loss: 0.023, Training Accuracy: 99.223%\n",
            "Epoch [10/10], Training Loss: 0.020, Training Accuracy: 99.358%\n",
            "Done Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing the AI Model\n",
        "\n",
        "- The accuracy of **99.xxx%** on the test images, it appears that the network has been effectively trained.\n",
        "- The high accuracy score suggests that the model has successfully learned to make correct predictions on **unseen data**, indicating a good generalization capability.\n",
        "- Please note that while high accuracy is encouraging, it's typically beneficial to review other performance metrics.\n",
        "  - like **precision**, **recall**, and **F1 score**\n",
        "  - to fully understand the model's performance, especially in case of imbalanced data sets."
      ],
      "metadata": {
        "id": "XkRwFj503tMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn off gradient calculation for efficiency during evaluation\n",
        "with torch.no_grad():\n",
        "    # Initialize variables to track the number of correctly predicted samples and the total number of samples\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # Iterate over batches of data in the test dataset\n",
        "    for images, labels in test_loader:\n",
        "        # Move the input images and labels to the appropriate device (e.g., CPU or GPU)\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Flatten the input images into a 1D tensor\n",
        "        images = images.view(-1, 28*28)\n",
        "\n",
        "        # Forward pass: compute the predicted outputs by passing the input images through the network\n",
        "        outputs = net(images)\n",
        "\n",
        "        # Compute the predicted classes by selecting the class with the highest probability\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        # Update the total count of samples\n",
        "        total += labels.size(0)\n",
        "\n",
        "        # Update the count of correctly predicted samples by comparing predicted labels with true labels\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # Calculate the accuracy of the network on the test images\n",
        "    accuracy = 100 * correct / total\n",
        "\n",
        "    # Print the accuracy of the network on the test dataset\n",
        "    print('Accuracy of the network on the test images: {:.2f} %'.format(accuracy))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAJPxub_s7nV",
        "outputId": "9378296e-92e9-4d57-a02c-e6b8643eed45"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the test images: 99.55 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize variables to store true positives, false positives, and false negatives\n",
        "true_positives = 0\n",
        "false_positives = 0\n",
        "false_negatives = 0\n",
        "\n",
        "# Turn off gradient tracking for evaluation\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        # Move tensors to the configured device\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        images = images.view(-1, 28*28)\n",
        "\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        # Calculate true positives, false positives, and false negatives\n",
        "        for pred, true_label in zip(predicted, labels):\n",
        "            if pred == 1 and true_label == 1:\n",
        "                true_positives += 1\n",
        "            elif pred == 1 and true_label == 0:\n",
        "                false_positives += 1\n",
        "            elif pred == 0 and true_label == 1:\n",
        "                false_negatives += 1\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) != 0 else 0\n",
        "recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) != 0 else 0\n",
        "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
        "\n",
        "# Print precision, recall, and F1 score\n",
        "print('Precision: {:.4f}'.format(precision))\n",
        "print('Recall: {:.4f}'.format(recall))\n",
        "print('F1 Score: {:.4f}'.format(f1_score))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDp51AyF_DN0",
        "outputId": "84280039-2cef-4a00-9b3b-ef9b4f6359cb"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "F1 Score: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Test Results\n",
        "- **Precision: 1.0000**\n",
        "  - Precision measures the accuracy of positive predictions. A precision of 1.0000 means that all the instances predicted as positive (e.g., belonging to a certain class) were indeed positive. In other words, there were no false positives in the predictions.\n",
        "\n",
        "- **Recall: 1.0000**\n",
        "  - Recall (also known as sensitivity) measures the ability of the classifier to correctly identify all positive instances. A recall of 1.0000 indicates that all the positive instances in the dataset were correctly identified by the classifier. There were no false negatives.\n",
        "\n",
        "- **F1 Score: 1.0000**\n",
        "  - The F1 score is the harmonic mean of precision and recall, providing a balance between the two metrics. A perfect F1 score of 1.0000 implies that both precision and recall are perfect. In this case, it suggests that the model's predictions are both precise and comprehensive, with no false positives or false negatives.\n",
        "\n",
        "Overall, these results indicate that the model performed exceptionally well on the test dataset, achieving perfect precision, recall, and F1 score. This suggests that the model's predictions are accurate and reliable, with no misclassifications. However, it's essential to consider the possibility of overfitting or biases in the dataset when interpreting such perfect scores. Further evaluation on diverse datasets would help validate the model's generalization performance.\n"
      ],
      "metadata": {
        "id": "SnoaDNYt_aH8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6bxrg0YK_2qz"
      },
      "execution_count": 190,
      "outputs": []
    }
  ]
}