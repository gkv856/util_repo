{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Why Use PyTorch?\n",
        "\n",
        "PyTorch is an open-source machine learning library for Python, developed primarily by Facebook's artificial intelligence research group. The main reason why PyTorch has gained popularity is its complete ease of use and flexibility.\n",
        "\n",
        "![PyTorch Logo](https://upload.wikimedia.org/wikipedia/commons/thumb/c/c6/PyTorch_logo_black.svg/2560px-PyTorch_logo_black.svg.png)\n",
        "\n"
      ],
      "metadata": {
        "id": "afHyozmeRnmX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dynamic Computation Graphs\n",
        "\n",
        "A key feature that differentiates PyTorch from other deep learning libraries is its dynamic computation graph.\n",
        "\n",
        "- A computation graph is an abstract way to represent your mathematical computations which are happening in the code.\n",
        "- The graph is essential as it allows you to not only visualize the computation but also compute the gradients automatically.\n",
        "- [Computation Graph Blog](https://towardsdatascience.com/getting-started-with-pytorch-part-1-understanding-how-automatic-differentiation-works-5008282073ec)\n",
        "\n",
        "In static computation graph (used in libraries like TensorFlow), the graph is defined in advance and then executed. However, in Pytorch:\n",
        "- Operations can be executed immediately, making debugging easier.\n",
        "- The overall experience is closer to the usual Python programming.\n",
        "\n"
      ],
      "metadata": {
        "id": "SmH_jj8pSz6T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Role of Differentiation and Chain Rule\n",
        "\n",
        "Differentiation is a crucial part of any deep learning library.\n",
        "\n",
        "- PyTorch uses a technique called automatic differentiation, which numerically evaluates the derivative of a function.\n",
        "- It is beneficial when dealing with complex equations, such as the ones we encounter in deep learning models.\n",
        "\n",
        "The Chain Rule:\n",
        "- It is used for differentiating compositions of functions.\n",
        "- This rule is central to backpropagation which is used for training neural networks.\n",
        "- The ability to compute gradients or derivatives of our error or loss with respect to our model's parameters, using the chain rule, allows us to optimize our model."
      ],
      "metadata": {
        "id": "N8wWbHhNThRg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A Beginner's Guide to Tensors\n",
        "\n",
        "## What is a Tensor?\n",
        "\n",
        "Just as kids can arrange their toys in many ways, data in computing can also be arranged in various forms. Imagine you're in a toy store.\n",
        "\n",
        "- An action figure sitting alone represents a single number, also known as a **scalar** in mathematics. A scalar only has a magnitude (its price in our case).\n",
        "- Action figures arranged in a row represent a one-dimensional array, popularly known as a **vector** in computing and mathematics.\n",
        "- Multiple rows and columns of action figures showcased in a glass box constitute a two-dimensional array or a **matrix**.\n",
        "- And lastly, a pile of such glass boxes stacked over each other forms a three-dimensional array, known as a **tensor**.\n",
        "\n",
        "A tensor, in essence, can house data in N dimensions but visualizing dimensions beyond the third one can be quite challenging.\n"
      ],
      "metadata": {
        "id": "-S7OWF95Tpzz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensors in PyTorch\n",
        "\n",
        "In the context of PyTorch (a popular library for deep learning), a tensor is pretty similar to NumPy's ndarray, and serves as the core data structure of the library.\n",
        "\n",
        "The three main components associated with tensors in PyTorch are:\n",
        "\n",
        "- **Grad**: It holds the value of gradient. PyTorch provides automatic differentiation and gradient computation which is executed when `.backward()` function is called.\n",
        "\n",
        "- **Grad_fn**: It is the backward function through which the gradient has been computed.\n",
        "\n",
        "- **Data**: This gives access to the raw data of the tensor.\n"
      ],
      "metadata": {
        "id": "022MlScSUk7E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#pyTorch hands on\n"
      ],
      "metadata": {
        "id": "WtUrYn23Rb6J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "99UIpL4hNXz5"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.tensor([123]) # list\n",
        "print(t1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOrpLCqcUsR_",
        "outputId": "37e76c85-230c-435b-c342-7c012b71f1c3"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([123])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t2 = torch.tensor([1, 3, 56]) # list\n",
        "t2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpv8FzozbYi4",
        "outputId": "b36f5220-8edc-4746-a708-c9f0e545945d"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1,  3, 56])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t3 = torch.tensor([[71, 63, 56], [41, 33, 36], [12, 13, 56]]) #matrix or 2d array\n",
        "t3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXKjbfDcsiEs",
        "outputId": "7319717d-98b3-4692-d4a4-61d004e467e0"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[71, 63, 56],\n",
              "        [41, 33, 36],\n",
              "        [12, 13, 56]])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t4 = torch.rand((2, 2, 3,  4)) # 4d tensor\n",
        "t4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgwSIp73ajpm",
        "outputId": "8af36345-cf71-4fe5-ea6b-badebb2f159b"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0.0489, 0.9811, 0.4841, 0.4563],\n",
              "          [0.3645, 0.2804, 0.5648, 0.4291],\n",
              "          [0.9350, 0.4427, 0.5392, 0.8962]],\n",
              "\n",
              "         [[0.7038, 0.4302, 0.4793, 0.7330],\n",
              "          [0.0926, 0.9524, 0.0857, 0.2026],\n",
              "          [0.9109, 0.0585, 0.2108, 0.7303]]],\n",
              "\n",
              "\n",
              "        [[[0.1812, 0.4382, 0.7901, 0.5384],\n",
              "          [0.5782, 0.1085, 0.7891, 0.9329],\n",
              "          [0.6105, 0.7977, 0.8257, 0.6815]],\n",
              "\n",
              "         [[0.6770, 0.2644, 0.1489, 0.8949],\n",
              "          [0.0603, 0.9511, 0.7097, 0.5604],\n",
              "          [0.4057, 0.6561, 0.9403, 0.4030]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t5 = torch.rand((2, 2, 2, 3,  4)) # 5d tensor\n",
        "t5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P32Y2M8BUvU4",
        "outputId": "6b6b6aa2-cf5f-49f4-d358-f3694d5b7b25"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[[0.0195, 0.0718, 0.0408, 0.4122],\n",
              "           [0.1932, 0.3714, 0.1908, 0.5408],\n",
              "           [0.9145, 0.2711, 0.3356, 0.0522]],\n",
              "\n",
              "          [[0.7831, 0.5051, 0.2124, 0.3839],\n",
              "           [0.6802, 0.2406, 0.5145, 0.6626],\n",
              "           [0.7313, 0.0279, 0.7054, 0.2339]]],\n",
              "\n",
              "\n",
              "         [[[0.7337, 0.8441, 0.1138, 0.5090],\n",
              "           [0.9958, 0.7904, 0.9044, 0.6528],\n",
              "           [0.3413, 0.8062, 0.3226, 0.4173]],\n",
              "\n",
              "          [[0.4480, 0.7880, 0.5059, 0.5101],\n",
              "           [0.0024, 0.8525, 0.8226, 0.5282],\n",
              "           [0.6375, 0.6496, 0.0796, 0.2182]]]],\n",
              "\n",
              "\n",
              "\n",
              "        [[[[0.9428, 0.4299, 0.9727, 0.4544],\n",
              "           [0.6792, 0.5054, 0.8887, 0.5914],\n",
              "           [0.1302, 0.2394, 0.2619, 0.3313]],\n",
              "\n",
              "          [[0.2020, 0.5461, 0.6350, 0.9905],\n",
              "           [0.3647, 0.2360, 0.1910, 0.7543],\n",
              "           [0.9175, 0.7514, 0.7033, 0.2516]]],\n",
              "\n",
              "\n",
              "         [[[0.8499, 0.9880, 0.8369, 0.2252],\n",
              "           [0.8480, 0.8535, 0.5727, 0.2377],\n",
              "           [0.3985, 0.7663, 0.0709, 0.4141]],\n",
              "\n",
              "          [[0.3798, 0.0128, 0.2381, 0.4857],\n",
              "           [0.6121, 0.5328, 0.1162, 0.4439],\n",
              "           [0.0460, 0.4580, 0.9655, 0.6359]]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1.shape, t2.shape, t3.shape, t4.shape, t5.shape,"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MS0b_g-RtWJU",
        "outputId": "ee034537-c7c8-464f-d4ef-8834434571f0"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1]),\n",
              " torch.Size([3]),\n",
              " torch.Size([3, 3]),\n",
              " torch.Size([2, 2, 3, 4]),\n",
              " torch.Size([2, 2, 2, 3, 4]))"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data types in Tensor\n",
        "\n",
        "[All datatypes of Tensor in pyTorch](https://pytorch.org/docs/stable/tensors.html)"
      ],
      "metadata": {
        "id": "tGw6QlVXtV1X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t_float = torch.tensor([1, 3, 56], dtype=torch.float64) # list\n",
        "t_float"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnflUULFthQz",
        "outputId": "97941cec-2572-4fe8-b0c4-5825cda22954"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1.,  3., 56.], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Math Operations on Tensors\n"
      ],
      "metadata": {
        "id": "KeSiYIQkt-ea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# common functions\n",
        "a = torch.rand(2, 4) * 2 - 1\n",
        "print('Common functions:')\n",
        "print(\"Absolute\", torch.abs(a))\n",
        "print(\"Ceiling\", torch.ceil(a))\n",
        "print(\"Floor\", torch.floor(a))\n",
        "print(\"Clamp\", torch.clamp(a, -0.5, 0.5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fo-m3xsyt80E",
        "outputId": "6fdd0ec1-6ace-4f13-e8e4-ee259f34d8ed"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Common functions:\n",
            "Absolute tensor([[0.6566, 0.5836, 0.3394, 0.7274],\n",
            "        [0.6814, 0.4508, 0.8396, 0.6929]])\n",
            "Ceiling tensor([[1., 1., 1., -0.],\n",
            "        [-0., 1., 1., 1.]])\n",
            "Floor tensor([[ 0.,  0.,  0., -1.],\n",
            "        [-1.,  0.,  0.,  0.]])\n",
            "Clamp tensor([[ 0.5000,  0.5000,  0.3394, -0.5000],\n",
            "        [-0.5000,  0.4508,  0.5000,  0.5000]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "# trigonometric functions and their inverses\n",
        "angles = torch.tensor([0, math.pi, math.pi / 4, math.pi / 2, 3 * math.pi / 4])\n",
        "sines = torch.sin(angles)\n",
        "inverses = torch.asin(sines)\n",
        "print('\\nSine and arcsine:')\n",
        "print(angles)\n",
        "print(sines)\n",
        "print(inverses)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxRgFy-8uVIh",
        "outputId": "a56ab4ae-8434-43e1-c605-9c33bad0051d"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sine and arcsine:\n",
            "tensor([0.0000, 3.1416, 0.7854, 1.5708, 2.3562])\n",
            "tensor([ 0.0000e+00, -8.7423e-08,  7.0711e-01,  1.0000e+00,  7.0711e-01])\n",
            "tensor([ 0.0000e+00, -8.7423e-08,  7.8540e-01,  1.5708e+00,  7.8540e-01])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# comparisons:\n",
        "print('\\nBroadcasted, element-wise equality comparison:')\n",
        "d = torch.tensor([[1., 2.], [3., 4.]])\n",
        "e = torch.ones(1, 2)  # many comparison ops support broadcasting!\n",
        "print(torch.eq(d, e)) # returns a tensor of type bool"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfDAk_fXu2vR",
        "outputId": "bf307c82-4a15-448a-92e7-9b883be044c8"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Broadcasted, element-wise equality comparison:\n",
            "tensor([[ True, False],\n",
            "        [False, False]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tensor Reduction/Aggregation\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-qoABM99u-go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reductions:\n",
        "d = torch.tensor([[1., 2.], [3., 4.]])\n",
        "print('\\nReduction ops:')\n",
        "print(torch.max(d))        # returns a single-element tensor\n",
        "print(torch.max(d).item()) # extracts the value from the returned tensor\n",
        "print(torch.mean(d))       # average\n",
        "print(torch.std(d))        # standard deviation\n",
        "print(torch.prod(d))       # product of all numbers\n",
        "print(torch.unique(torch.tensor([1, 2, 1, 2, 1, 2]))) # filter unique elements"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Q-BLk2mu3bu",
        "outputId": "d7914721-e27b-4800-de8a-99b578eeb44f"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Reduction ops:\n",
            "tensor(4.)\n",
            "4.0\n",
            "tensor(2.5000)\n",
            "tensor(1.2910)\n",
            "tensor(24.)\n",
            "tensor([1, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tensor Reduction/Aggregation along rows and columns\n",
        "\n"
      ],
      "metadata": {
        "id": "9pCEQ3_wvZXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reductions:\n",
        "d = torch.tensor([[1., 2.], [3., 4.]])\n",
        "print('\\nReduction ops:')\n",
        "print(torch.mean(d))       # average\n",
        "print(torch.mean(d, dim=1))       # average each row\n",
        "print(torch.mean(d, dim=0))       # average each col"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxZYA0Fxvdhy",
        "outputId": "ec58f502-d7f8-440a-dce5-5f03dc61e199"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Reduction ops:\n",
            "tensor(2.5000)\n",
            "tensor([1.5000, 3.5000])\n",
            "tensor([2., 3.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Manipulating Tensor Shapes\n",
        "- This is the one of the most important if not the most important topic."
      ],
      "metadata": {
        "id": "k7rsfYHWRbVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.rand(2, 3, 4)\n",
        "a.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8QZ3WwxwSLM",
        "outputId": "7058d335-f660-4376-fc69-4d40eb909478"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dq98um-52YG2",
        "outputId": "847620e8-02b7-41eb-f2e7-8c1b3d6869d8"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.7132, 0.4561, 0.4247, 0.8297],\n",
              "         [0.8061, 0.6957, 0.3318, 0.5511],\n",
              "         [0.1921, 0.1468, 0.1033, 0.5926]],\n",
              "\n",
              "        [[0.2604, 0.6975, 0.6360, 0.4886],\n",
              "         [0.5887, 0.4280, 0.0127, 0.4609],\n",
              "         [0.2093, 0.2102, 0.1929, 0.3554]]])"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.view(-1, 1).shape, a.view(-1, 2).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BZMdkuq2ZvW",
        "outputId": "7cebe443-c3a8-4fc6-ad75-c487ee061d4b"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([24, 1]), torch.Size([12, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# you dont need -1 all the time, if you know the exact dim, then you can use that\n",
        "# 2x3x4 = total 24\n",
        "\n",
        "a.view(4, 6), a.view(4, 6).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAwldLoH2br4",
        "outputId": "661871ad-11d4-4f8d-9a4d-fe4d4e8124d7"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.7132, 0.4561, 0.4247, 0.8297, 0.8061, 0.6957],\n",
              "         [0.3318, 0.5511, 0.1921, 0.1468, 0.1033, 0.5926],\n",
              "         [0.2604, 0.6975, 0.6360, 0.4886, 0.5887, 0.4280],\n",
              "         [0.0127, 0.4609, 0.2093, 0.2102, 0.1929, 0.3554]]),\n",
              " torch.Size([4, 6]))"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# you dont need -1 all the time, if you know the exact dim, then you can use that\n",
        "# 2x3x4 = total 24\n",
        "\n",
        "a.view(4, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "J4EH2Flv3JJC",
        "outputId": "c5ec2827-b0b4-4d22-aadb-327ac326d052"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "shape '[4, 10]' is invalid for input of size 24",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-21b097f6e71c>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# 2x3x4 = total 24\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[4, 10]' is invalid for input of size 24"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rand vs Randn\n",
        "- Rand gives random number from 0 to 1\n",
        "- Randn also gives random number from a normal distribution where mean is 0 and variance of 1"
      ],
      "metadata": {
        "id": "dXpztlFARh5-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "torch.rand(2, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6bNSG563vdT",
        "outputId": "d66d86fb-05ba-476c-da4f-e2ecfa8caaea"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8823, 0.9150, 0.3829],\n",
              "        [0.9593, 0.3904, 0.6009]])"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.randn(2, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cvMJKKN3yX3",
        "outputId": "3bc41728-553a-4c25-ec4a-aba578a5b8a3"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4528, 0.6410, 0.5200],\n",
              "        [0.5567, 0.0744, 0.7113]])"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# random integers between 3 and 10, 10 excluded of the provided shape\n",
        "x = torch.randint(3, 10, (3, 4))\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktsPXQwZ4PjZ",
        "outputId": "da1e3bf7-6e1b-4903-e102-fd96537e8345"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[9, 6, 3, 4],\n",
              "        [9, 6, 7, 5],\n",
              "        [9, 8, 7, 8]])"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.numel(x) # number of elements in the tensor, in this case, 3x4 = 12"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQMkeWGb7HJw",
        "outputId": "9388c9b1-6126-4a5f-9d5d-5788f83728a5"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Zeros, Ones, and Likes\n",
        "\n",
        "# Practical UseCases for PyTorch's `torch.ones`, `zeros`, `like`\n",
        "\n",
        "PyTorch provides several functions to create tensors. Three of them are `torch.ones`, `torch.zeros`, and `torch.ones_like`, `torch.zeros_like`. Let's take a look at practical scenarios where these can be used.\n",
        "\n",
        "## torch.ones\n",
        "\n",
        "`torch.ones` is used to create a tensor filled with the scalar value 1, with the shape defined by the variable argument size.\n",
        "\n",
        "### Use case:\n",
        "- Initialization of bias or weights in a neural network: `torch.ones` can be used fill the weights or bias tensor with initial value of 1.\n",
        "\n",
        "    ```python\n",
        "    bias = torch.ones((10,))\n",
        "    weights = torch.ones((5, 10))\n",
        "    ```\n",
        "\n",
        "- Generation of a mask tensor: For certain operations where we needs apply a mask to all elements.\n",
        "\n",
        "    ```python\n",
        "    mask = torch.ones_like(weights)\n",
        "    ```\n",
        "\n",
        "## torch.zeros\n",
        "\n",
        "`torch.zero` creates a tensor filled with the scalar value 0, with the shape defined by the variable argument size.\n",
        "\n",
        "### Use case:\n",
        "- Creation of a black image or background in computer vision tasks.\n",
        "    ```python\n",
        "    black_img = torch.zeros([256, 256, 3])\n",
        "    ```\n",
        "- Padding values in data analytics.\n",
        "    ```python\n",
        "    padded_sequence = torch.zeros(max_sequence_length, dtype=int)\n",
        "    padded_sequence[:len(sequence)] = torch.tensor(sequence)\n",
        "    ```\n",
        "- In deep learning, to initialize the weights or bias tensor with zeros before training.\n",
        "    ```python\n",
        "    weights = torch.zeros((5, 10))\n",
        "    ```\n",
        "- Generation of a masking tensor.\n",
        "\n",
        "## torch.ones_like and torch.zeros_like\n",
        "\n",
        "These functions come handy when ones need to create a new tensor that has the same size as a given tensor. The new tensor is then filled with ones or zeros respectively.\n",
        "\n",
        "### Use case:\n",
        "\n",
        "```python\n",
        "x = torch.randn((5, 5))\n",
        "\n",
        "# creating tensor with same size as x\n",
        "ones = torch.ones_like(x)\n",
        "zeros = torch.zeros_like(x)\n",
        "```\n",
        "\n",
        "Operations like initializing tensors, creating masks, generating images, and padding sequences are just some of the areas where these functions are vital. Their application is versatile and extend to many other fields of machine learning, deep learning and data analytics."
      ],
      "metadata": {
        "id": "Ao_6gYJc7ahJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ones = torch.ones((2, 4))\n",
        "ones"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbQlIIx87Tlv",
        "outputId": "33d79e3f-19dc-4a83-f3f4-0c7affb1f937"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ones = torch.ones((2, 4), dtype=torch.float64)\n",
        "ones"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3t_qnKt7iPS",
        "outputId": "f60cec9f-2859-4ad9-973d-e3611ce40c42"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zeros = torch.zeros((2, 4))\n",
        "zeros"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCfdbwf47olq",
        "outputId": "523addfa-ad4a-49a9-b80a-7f9c5b36cd9d"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_tensor = torch.rand_like(zeros, dtype=torch.float64)\n",
        "new_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8MTKbnY7tDZ",
        "outputId": "5ac793ad-0b57-44a4-ebf3-0c6d4656aead"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8456, 0.3843, 0.0993, 0.6626],\n",
              "        [0.5819, 0.7093, 0.4720, 0.0938]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.tensor([1, 2, 3])\n",
        "t2 = torch.tensor([1, 2, 3])\n",
        "\n",
        "t3 = t1.add(t2)\n",
        "t3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfUCVu_E8A-A",
        "outputId": "8107da19-2766-47f5-a0d1-77a8357c6ce4"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2, 4, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1, t2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uZjx1McBBU8",
        "outputId": "8c860a61-d79f-4533-ef37-9af183431261"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1, 2, 3]), tensor([1, 2, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inplace addition. Similarly you can do any operation inplace\n",
        "t1.add_(t2)\n",
        "t1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHf35IhtBEXI",
        "outputId": "b7e19cbf-fd09-4c76-cc22-e12041b57c64"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2, 4, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Understanding AutoGrad\n",
        "\n",
        "PyTorch's `autograd` package provides classes and functions implementing automatic differentiation of arbitrary scalar-valued functions. It allows for on-the-fly operation tracking on tensors, where every operation is recorded on a graph. The graph is then used in the backward pass to compute gradients.\n",
        "\n",
        "## Definition of Autograd\n",
        "\n",
        "`autograd` is PyTorch’s automatic differentiation library. It keeps a record of all operations performed on a tensor and creates an acyclic computation graph. This allows the use of back-propagation to calculate the gradients of the weights with respect to the loss function, which is essential when training neural networks.\n",
        "\n",
        "## Importance of Autograd\n",
        "\n",
        "In machine learning, especially in neural networks, optimization of weights is done using gradient information. Gradients point the optimizer in the direction towards which the parameters should be altered for minimizing the loss function. Autograd automates the computation of the backward pass in a computational graph (which are the gradients). Hence, calculation of gradients is performed automatically and accurately.\n",
        "\n",
        "## How Autograd works\n",
        "\n",
        "- When a tensor's `.requires_grad` property is set as `True`, PyTorch starts to track all operations on it.\n",
        "- After the computation is finished, `.backward()` is called and all gradients are computed automatically.\n",
        "- The gradient for a tensor will be accumulated into `.grad` attribute.\n",
        "- To prevent tracking history and the use of memory, `.detach()` is called to stop tracking computations.\n",
        "- Tracking can also be stopped by wrapping the code block inside `with torch.no_grad():`\n",
        "\n",
        "Here is an example demonstrating autograd:\n",
        "\n",
        "```python\n",
        "x = torch.randn(3, 3, requires_grad=True)\n",
        "y = x + 2\n",
        "z = y * y * 3\n",
        "out = z.mean()\n",
        "out.backward()  # computes gradients\n",
        "print(x.grad)  # the gradient of 'out' with respect to 'x'\n",
        "```\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "The usage of `autograd` simplifies the computation of gradients in neural networks. By automatically calculating gradients, it reduces the likelihood of making errors in complex neural networks, and hence improves efficiency of the model training phase."
      ],
      "metadata": {
        "id": "2KXQ9qiiBix8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([1., 2., 3.], requires_grad=True)\n",
        "y = x + 2\n",
        "z = y * y * 3\n",
        "out = z.mean()\n",
        "out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZppqQsdBGU1",
        "outputId": "d14698a9-7c08-4030-e29c-6b5ee6ffd70c"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(50., grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this wont work because backword is not yet called\n",
        "print(x.grad)  # the gradient of 'out' with respect to 'x'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYh1B5cSCTaF",
        "outputId": "2a455211-da59-4431-d447-f2660f2c6406"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# before calling the backward, lets have a look at the grad functions of each\n",
        "\n",
        "y.grad_fn, z.grad_fn, out.grad_fn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLY9xjrPDSZD",
        "outputId": "7bca8f47-1fc9-4ef7-ead0-9f2140c5c989"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<AddBackward0 at 0x7ff63979f220>,\n",
              " <MulBackward0 at 0x7ff63979fee0>,\n",
              " <MeanBackward0 at 0x7ff63979ec20>)"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##The Backward Function\n",
        "\n",
        "The `backward()` function in PyTorch is a critical part of the Autograd system, which is responsible for automatic computation of gradients for various operations on Tensors.\n",
        "\n"
      ],
      "metadata": {
        "id": "EtyZFOWEDkh_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Functionality of the `backward()` Function\n",
        "\n",
        "The `backward()` function is primarily used for computing the gradients of the loss with respect to some set of variables (usually the model parameters). It performs backpropagation starting from a variable.\n",
        "\n",
        "Here's how it works:\n",
        "\n",
        "- The `backward()` function computes the gradient/differentiation of the current tensor w.r.t. graph leaves.\n",
        "- The graph is defined by following all the operations from the leaf/leaves to the current tensor.\n",
        "- If the current tensor (`y`) is a scalar (i.e., it holds a one-element data), then you don’t need to specify any arguments to `backward()`. However, if it has more elements, you need to specify a gradient argument that is a tensor of matching shape (to `y`).\n",
        "\n"
      ],
      "metadata": {
        "id": "xKIoxZuQD7db"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example of how `backward()` works:\n",
        "\n",
        "Here is a simple example:\n",
        "\n",
        "```python\n",
        "import torch\n",
        "\n",
        "# Create a tensor and set requires_grad=True to track computation with it\n",
        "x = torch.ones(2, 2, requires_grad=True)\n",
        "\n",
        "# Perform a tensor operation\n",
        "y = x + 2\n",
        "\n",
        "# Perform more operations on y\n",
        "z = y * y * 3\n",
        "out = z.mean()\n",
        "\n",
        "# Trigger the backpropagation with backward()\n",
        "out.backward()\n",
        "\n",
        "# Print gradients d(out)/dx\n",
        "print(x.grad)\n",
        "```\n",
        "\n",
        "In the above code:\n",
        "- We first define a tensor `x` with `requires_grad=True` to ensure that the operation should be recorded for gradient computation.\n",
        "- We then perform several operations on `x` to get the output tensor `out`.\n",
        "- Calling the `backward` function triggers backpropagation, computation of the gradient.\n",
        "- Finally, the gradients are available in `x.grad`.\n",
        "\n",
        "### Conclusion\n",
        "\n",
        "The `backward()` function is essential for neural network training. With this function, PyTorch allows automatic and efficient gradient computations. This simplifies the implementation of many machine learning algorithms, making development faster and less error-prone."
      ],
      "metadata": {
        "id": "ol-SmqPtD9XV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out.backward( )  # computes gradients\n",
        "print(x.grad)  # the gradient of 'out' with respect to 'x'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTAbZpIDBqGh",
        "outputId": "c6a7ee74-7897-4261-d208-ac3291380608"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 6.,  8., 10.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loss function in pyTorch\n",
        "- [Every loss available in pyTorch](https://pytorch.org/docs/stable/nn.html#loss-functions)"
      ],
      "metadata": {
        "id": "2_cVP2R7GhEj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "cnjsnlx7GzUr"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#without any reduction\n",
        "loss_mse = nn.MSELoss(reduction=\"none\")\n",
        "input = torch.randn(3, 4, requires_grad=True)\n",
        "target = torch.randn(3, 4)\n",
        "loss = loss_mse(input, target)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoRKcc2kBv_Z",
        "outputId": "3faad2b9-48c2-48f8-cc15-3b66cfaa602d"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0107, 2.1891, 0.2098, 2.1428],\n",
              "        [0.2858, 1.6717, 0.1127, 2.5816],\n",
              "        [1.3416, 0.1585, 0.8656, 0.3567]], grad_fn=<MseLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# in general we want to have one single value of the loss\n",
        "loss_mse = nn.MSELoss(reduction=\"sum\")\n",
        "loss = loss_mse(input, target)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8IjlOqDG45N",
        "outputId": "3dc1d7bb-0c93-463e-f527-36581fb142d4"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(11.9265, grad_fn=<MseLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# in general we want to have one single value of the loss\n",
        "loss_mse = nn.MSELoss(reduction=\"mean\")\n",
        "loss = loss_mse(input, target)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHvi_lbQHuwj",
        "outputId": "6404c757-db42-49f7-eeab-d22e384b4b02"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9939, grad_fn=<MseLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    }
  ]
}